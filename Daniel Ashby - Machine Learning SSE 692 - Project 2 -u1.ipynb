{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Project Statement\n",
    " ============\n",
    " As with Project 1, apply the ideas of ch. 1 - 3 as appropriate.\n",
    " Develop and demonstrate your capabilities with:\n",
    "  * Regression (ch. 4)\n",
    "  * Support Vector Machines (SVM's) (ch. 5)\n",
    "\n",
    "\n",
    "  Starting Point\n",
    "  --------------\n",
    "  To start this project I'm going to pull from the Titanic dataset part of the previous, since I was a little disappointed that Derek Byrnes got a higher score than me. Friendly rivalry and what not. :) So now that we're working together, I'll see if I can pull some of his techniques in to produce a better score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "\n",
    "raw_training = pandas.read_csv(\"titanic/train.csv\")\n",
    "raw_test = pandas.read_csv(\"titanic/test.csv\")\n",
    "example_output = pandas.read_csv(\"titanic/gender_submission.csv\")\n",
    "\n",
    "y = raw_training[\"Survived\"].copy()\n",
    "X = raw_training.drop(\"Survived\", axis=1)\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import re\n",
    "\n",
    "class RegexTransform(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, regex=\".*\", groupNum=0):\n",
    "        self.regex = re.compile(regex)\n",
    "        self.groupNum = groupNum\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        return X.applymap((lambda x: RegexTransform.applyRegex(x, self)))\n",
    "    \n",
    "    @staticmethod\n",
    "    def applyRegex(val, transObj):\n",
    "        if (type(val) is str):\n",
    "            match = transObj.regex.search(val)\n",
    "            newVal = \"\"\n",
    "            if (match):\n",
    "                newVal = match.group(transObj.groupNum)\n",
    "            if (newVal is None):\n",
    "                newVal = \"\"\n",
    "            return newVal\n",
    "        else:\n",
    "            return val\n",
    "\n",
    "\n",
    "regexTest = RegexTransform(regex=\"(.*?),\", groupNum=1)\n",
    "results = regexTest.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, KBinsDiscretizer\n",
    "\n",
    "def getOneHotEncoderColumns(encoder, colNames):\n",
    "    names = []\n",
    "    i = 0\n",
    "    for cat_cols in encoder.categories_:\n",
    "        curColName = colNames[i]\n",
    "        i += 1\n",
    "        for cat in cat_cols:\n",
    "            names.append(curColName + \"_\" + str(cat))\n",
    "    return names\n",
    "\n",
    "class TitanicDataTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, numeric_scale=True, numeric_nBins=5, numeric_encode=\"ordinal\", numeric_strategy=\"quantile\"):\n",
    "        numeric_steps=[\n",
    "            ('imputer', SimpleImputer()),\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('discretizer', KBinsDiscretizer(n_bins=numeric_nBins,encode=numeric_encode,strategy=numeric_strategy))\n",
    "        ]\n",
    "        self.numeric_pipeline = Pipeline(numeric_steps)\n",
    "\n",
    "        self.categorical_pipeline = Pipeline(steps=[\n",
    "            ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "            ('onehot', OneHotEncoder(sparse=False, handle_unknown ='ignore'))\n",
    "        ])\n",
    "\n",
    "        self.namesPipeline = Pipeline(steps=[\n",
    "            ('lastName', RegexTransform(regex=\"(.*?),\", groupNum=1)),\n",
    "            ('oneHot', OneHotEncoder(sparse=False, handle_unknown ='ignore'))\n",
    "        ])\n",
    "\n",
    "        self.column_transform = ColumnTransformer(sparse_threshold=0,transformers=[\n",
    "            ('numerical', self.numeric_pipeline, [\"Age\", \"Fare\"]),\n",
    "            ('categorical', self.categorical_pipeline, [\"Sex\", \"Embarked\", \"Pclass\"]),\n",
    "            ('passthrough', \"passthrough\", [\"SibSp\", \"Parch\"]),\n",
    "            ('names', self.namesPipeline, [\"Name\"])\n",
    "        ])\n",
    "    \n",
    "    def fit(self, data, labels=None):\n",
    "        self.column_transform.fit(data, labels)\n",
    "        \n",
    "        self.features = [\"Age\", \"Fare\" ]\n",
    "        name, pipeline, columns = self.column_transform.transformers_[1]\n",
    "        name, transform = pipeline.steps[-1]\n",
    "        self.features += getOneHotEncoderColumns(transform, columns)\n",
    "        self.features += [\"SibSp\", \"Parch\"]\n",
    "        name, pipeline, columns = self.column_transform.transformers_[3] \n",
    "        name, transform = pipeline.steps[-1]\n",
    "        self.features += getOneHotEncoderColumns(transform, columns)\n",
    "        return self\n",
    "    \n",
    "    def transform(self, data):\n",
    "        tmpData = self.column_transform.transform(data)\n",
    "\n",
    "        newNames = [\"Age\", \"Fare\" ]\n",
    "        name, pipeline, columns = self.column_transform.transformers_[1]\n",
    "        name, transform = pipeline.steps[-1]\n",
    "        newNames += getOneHotEncoderColumns(transform, columns)\n",
    "        newNames += [\"SibSp\", \"Parch\"]\n",
    "        name, pipeline, columns = self.column_transform.transformers_[3] \n",
    "        name, transform = pipeline.steps[-1]\n",
    "        newNames += getOneHotEncoderColumns(transform, columns)\n",
    "        \n",
    "        df = pandas.DataFrame(tmpData, columns=newNames)\n",
    "        #dummies = pandas.DataFrame(columns=self.features)\n",
    "        #return pandas.concat((df, dummies)).fillna(0)\n",
    "        return df\n",
    "\n",
    "titanicTransformer = TitanicDataTransformer()\n",
    "clean_training = titanicTransformer.fit_transform(X)\n",
    "\n",
    "print(clean_training.head())\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "name": "python"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
