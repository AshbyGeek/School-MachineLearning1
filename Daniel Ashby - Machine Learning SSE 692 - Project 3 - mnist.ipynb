{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 3\n",
    "## Problem Statement\n",
    "As with Project 1, apply the ideas of ch. 1 - 3 as appropriate.\n",
    "Develop and demonstrate your capabilities with:\n",
    "* Decision Trees (ch. 6)\n",
    "* Ensemble Learning and Random Forests (ch. 7)\n",
    "* Dimensionality Reduction (ch. 8)\n",
    "\n",
    "## Daniel's Task\n",
    "Apply ensembling tecniques to the mnist dataset to improve algorithm performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mnist Dataset Ensembling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-29T23:02:28.927363Z",
     "start_time": "2019-04-29T23:01:59.309293Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set:    (44800, 784)   (44800,)\n",
      "Validation set:  (11200, 784)   (11200,)\n",
      "Testing set:     (14000, 784)   (14000,)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as pyplot\n",
    "import numpy\n",
    "\n",
    "from sklearn.datasets import fetch_openml\n",
    "mnist = fetch_openml('mnist_784')\n",
    "X = mnist[\"data\"]\n",
    "y = mnist[\"target\"]\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test,  y_train, y_test  = train_test_split(X,       y,       test_size=0.2, random_state=31415)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Training set:   \", X_train.shape, \" \", y_train.shape)\n",
    "print(\"Validation set: \", X_valid.shape, \" \", y_valid.shape)\n",
    "print(\"Testing set:    \", X_test.shape,  \" \", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First I'm going to do a sanity check. If my results are similar to what I got in Project 1 then I'll know that I haven't clobbered anything too badly so far."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-29T23:03:56.860306Z",
     "start_time": "2019-04-29T23:02:28.929374Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9689285714285715\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "neighborsClsfr = KNeighborsClassifier(n_jobs=-1)\n",
    "neighborsClsfr.fit(X_train, y_train)\n",
    "print(neighborsClsfr.score(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks good! Now I'm going to try some new algorithms on this dataset\n",
    "\n",
    "## Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-29T23:04:01.110031Z",
     "start_time": "2019-04-29T23:03:56.861307Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.968125\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "randForest = RandomForestClassifier(n_estimators=100, n_jobs=-1, random_state=42)\n",
    "randForest.fit(X_train, y_train)\n",
    "print(randForest.score(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple enough (thanks scikit learn!) and the results look stellar. Good enough that I'm kind of suspicious that it's overfitting pretty badly. I'll run some cross validation to see if that seems to be the case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-29T23:04:19.826047Z",
     "start_time": "2019-04-29T23:04:01.112034Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.96430563 0.96172302 0.96819196 0.96505526 0.96393882]\n",
      "Avg: 0.9646 +/- 0.0021\n"
     ]
    }
   ],
   "source": [
    "rf_crossVal = cross_val_score(randForest, X_train, y_train, cv=5, n_jobs=-1, scoring=\"accuracy\")\n",
    "print(rf_crossVal)\n",
    "print(f\"Avg: {rf_crossVal.mean():0.4f} +/- {rf_crossVal.std():0.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yeah, those results are pretty consistent with each other. Still, won't really know until I compare against the test set. I'm going to save that for the very end though."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boosting\n",
    "Boosting sounds pretty cool and I want to try it out, so I'm going pull out the standard sci-kit learn booster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-29T23:05:03.359350Z",
     "start_time": "2019-04-29T23:04:19.827048Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7350892857142857\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "booster = AdaBoostClassifier()\n",
    "booster.fit(X_train, y_train)\n",
    "print(booster.score(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, that was less than dazzling so I'm going to try another booster that I've heard good things about. Still, I might come back to this at the end if my test dataset shows everything else to be horribly overfitted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost\n",
    "I listened to a podcast about XGBoost a while back and that guy seemed quite impressed by the performance of that library, so I installed it via `pip3 install xgboost`.\n",
    "Unfortunately it doesn't quite seem to like windows and didn't work out of the box. After a bit of poking around based on the error message I got I found that I could just move a couple files around in the python packages folder and it started working. Hopefully anyone else that tries this won't have that problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-29T23:07:09.571834Z",
     "start_time": "2019-04-29T23:05:03.360342Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9328571428571428\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "xbooster = XGBClassifier(n_jobs=-1)\n",
    "xbooster.fit(X_train, y_train)\n",
    "print (xbooster.score(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hey, not bad! Wonder if it will compare well with the other algorithms if I do some tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-29T23:07:09.579841Z",
     "start_time": "2019-04-29T23:07:09.572835Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9725223214285714\n"
     ]
    }
   ],
   "source": [
    "# param_grid = { \n",
    "#    \"learning_rate\": [0.05, 0.1, 0.2, 0.4],\n",
    "#    \"subsample\": [0.6, 0.75, 0.9],\n",
    "#    \"max_depth\": [2, 3, 5],\n",
    "#    \"gamma\": [0, 0.1, 0.3]\n",
    "#}\n",
    "#\n",
    "#search = GridSearchCV(xbooster, param_grid, n_jobs=-1, cv=4)\n",
    "#search.fit(X_train, y_train)\n",
    "#print(search.best_params_)\n",
    "#print(search.best_score_)\n",
    "#print(search.refit_time_)\n",
    "\n",
    "#results from the original 11 hour 6 minute run:\n",
    "search = {\n",
    "    \"best_params\": {'gamma': 0, 'learning_rate': 0.4, 'max_depth': 5, 'subsample': 0.9},\n",
    "    \"best_score\": 0.9725223214285714,\n",
    "    \"refit_time\": 169.8297770023346\n",
    "}\n",
    "\n",
    "xbooster.gamma = search[\"best_params\"][\"gamma\"]\n",
    "xbooster.learning_rate = search[\"best_params\"][\"learning_rate\"]\n",
    "xbooster.max_depth = search[\"best_params\"][\"max_depth\"]\n",
    "xbooster.subsample = search[\"best_params\"][\"subsample\"]\n",
    "\n",
    "print(search[\"best_score\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yup. That may be the best one so far."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Voting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-29T23:11:34.003772Z",
     "start_time": "2019-04-29T23:07:09.583350Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9766071428571429\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "estimators=[\n",
    "    ('xb', xbooster),\n",
    "    ('knn', neighborsClsfr),\n",
    "    ('randf', randForest)\n",
    "]\n",
    "voter = VotingClassifier(estimators=estimators)\n",
    "voter.fit(X_train, y_train)\n",
    "print(voter.score(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's even just a smidge better than xgboost, and this hasn't even been tuned. Though, tuning this beast would probably be quite a chore. For sake of time I'm going to dodge that mess and move on to bagging."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-29T23:20:26.915971Z",
     "start_time": "2019-04-29T23:11:34.005774Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9657142857142857\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "bagger = BaggingClassifier(KNeighborsClassifier(), max_samples=0.6, n_jobs=-1, random_state=42)\n",
    "bagger.fit(X_train, y_train)\n",
    "print(bagger.score(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Awesome, this one also looks really good."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing against the test set\n",
    "Now I'm going to see how all these hold up against my test set, which I have not used thus far. That will give me an idea of how badly I've overfitted everything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-30T00:35:17.151015Z",
     "start_time": "2019-04-30T00:19:29.416675Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier - 0.9674\n",
      "RandomForestClassifier - 0.9648\n",
      "AdaBoostClassifier - 0.7346\n",
      "XGBClassifier   - 0.9308\n",
      "VotingClassifier - 0.9739\n",
      "BaggingClassifier - 0.9646\n"
     ]
    }
   ],
   "source": [
    "compare_estimators = [\n",
    "    neighborsClsfr,\n",
    "    randForest,\n",
    "    booster,\n",
    "    xbooster,\n",
    "    voter,\n",
    "    bagger\n",
    "]\n",
    "\n",
    "for clf in compare_estimators:\n",
    "    score = clf.score(X_test, y_test)\n",
    "    print(f\"{type(clf).__name__: <15} - {score:0.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the validation and test accuracy results in a table:\n",
    "\n",
    "\n",
    "|Algorithm  | validation set | test set | difference |\n",
    "|-----------|----------------|----------|------------|\n",
    "| neighbors | 0.9689 | 0.9674 | 0.0015 |\n",
    "| randForest | 0.9681 | 0.9648 | 0.0033 |\n",
    "| Ada Boost | 0.7351 | 0.7346 | 0.0005 |\n",
    "| XGBoost | 0.9328 | 0.9308 | 0.0020 |\n",
    "| Voting | 0.9766 | 0.9739 | 0.0034 |\n",
    "| Bagging | 0.9657 | 0.9646 | 0.0011 |\n",
    "\n",
    "\n",
    "Without more test cases, perhaps via cross validation, these difference values can't be taken too literally, but they are still quite small so the chances of any of these being terrible overfit is pretty small. \n",
    "\n",
    "As a side note, this bagger took a very long time to score the test set, despite not scoring as well as the voting classifier. If I were going to use the bagger on this set I would first try a simpler algorithm on the backend or using fewer estimators."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Daniel Ashby Indirect Activity Report\n",
    "\n",
    "| Date | Duration | Duration in Minutes | Collaborator(s) | Specific Task/Activity |\n",
    "|:-------|:----|:---|:-|:-----------------------------|\n",
    "| 1/19/19 | 3:00 | 180 | - | Reading Textbook Chapters 1-3 |\n",
    "| 1/26/19 | 3:00 | 180 | - | Working on Project 1 |\n",
    "| 2/2/19 | 7:00 | 420 | - | Working on Project 1 |\n",
    "| 2/4/19 | 1:30 | 90 | - | Working on Project 1 |\n",
    "| 2/6/19 | 1:00 | 60 | - | Working on Project 1 |\n",
    "| 2/9/19 | 8:00 | 480 | - | Working on Project 1 |\n",
    "| 2/11/19 | 4:00 | 240 | - | Working on Project 1 |\n",
    "| - | - | - | - | - |\n",
    "| 2/16/19 | 3:00 | 180 | - | Reading Textbook |\n",
    "| 2/16/19 | 3:00 | 180 | - | Attempting to set up JupyterHub for collaboration |\n",
    "| 2/23/19 | 4:00 | 240 | - | Reading Textbook |\n",
    "| 3/2/19 | 3:00 | 180 | - | Attempting to set up JupyterHub for collaboration |\n",
    "| 3/9/19 | 6:00 | 360 | Derek Byrne | Improving Titanic scores |\n",
    "| 3/16/19 | 8:00 | 480 | Derek Byrne | Linear Regression |\n",
    "| 3/18/19 | 8:00 | 480 | Derek Byrne | Linear Regression, and Support Vector Classification |\n",
    "| - | - | - | - | - |\n",
    "| 3/30/19 | 6:00 | 360 | - | Reading Textbook |\n",
    "| 4/6/19 | 3:00 | 180 | - | Reading Textbook |\n",
    "| 4/20/19 | 4:00 | 240 | Derek Byrne | Reading Textbook & Project 3 |\n",
    "| 4/27 | 6:00 | 360 | Derek Byrne | Project 3 |\n",
    "| 4/29 | 1:30 | 90 | Derek Byrne | Project 3 |\n",
    "| - | - | - | - | - |\n",
    "| Sum for current report | 20:30 | 1,230 | - | - |\n",
    "| Cumulative sum for this course | 83:00 | 4,980 | - | - |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "457px",
    "left": "1099px",
    "right": "20px",
    "top": "118px",
    "width": "645px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
